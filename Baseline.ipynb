{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_8srpJnAyeS",
        "outputId": "832de51c-7e5d-4596-a786-31ff3a16b1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.0+cu121 (from versions: 2.2.0+cu121, 2.2.1+cu121, 2.2.2+cu121, 2.3.0+cu121, 2.3.1+cu121, 2.4.0+cu121, 2.4.1+cu121, 2.5.0+cu121, 2.5.1+cu121)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.0+cu121\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ===== PyTorch (CUDA 12.1) =====\n",
        "!pip install -q torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# ===== PyTorch Geometric (prebuilt wheels, no compilation) =====\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "# ===== Fairness + utilities =====\n",
        "!pip install -q fairlearn scikit-learn pandas numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Uje4FuYuA4RY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ananyabatra04/fairness-graph-gnn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hObEnkCJLXhb",
        "outputId": "4cc5e318-990a-40d3-8ba2-ee974b2f25b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairness-graph-gnn'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 25 (delta 0), reused 2 (delta 0), pack-reused 22 (from 1)\u001b[K\n",
            "Receiving objects: 100% (25/25), 52.29 MiB | 13.45 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Updating files: 100% (10/10), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = pd.read_csv(\"fairness-graph-gnn/datasets/region_job.csv\")\n",
        "feature_cols = [\n",
        "    c for c in nodes.columns\n",
        "    if c not in [\"user_id\", \"region\", \"I_am_working_in_field\"]\n",
        "]\n",
        "nodes[\"I_am_working_in_field\"].value_counts().sort_index()\n",
        "\n",
        "# Drop unknown labels\n",
        "nodes = nodes[nodes[\"I_am_working_in_field\"] != -1]\n",
        "\n",
        "# Binarize: 0 -> 0, 1–4 -> 1\n",
        "nodes[\"label\"] = (nodes[\"I_am_working_in_field\"] > 0).astype(int)\n",
        "\n",
        "nodes[\"label\"].value_counts()\n",
        "nodes[\"label\"].unique()\n"
      ],
      "metadata": {
        "id": "TXZNMIv9A5cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d791922d-ea8d-4552-9415-d6f817b3267c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor(\n",
        "    nodes[feature_cols].values,\n",
        "    dtype=torch.float\n",
        ")\n",
        "\n",
        "X = (X - X.mean(dim=0)) / (X.std(dim=0) + 1e-6) #normalization\n",
        "\n",
        "\n",
        "y = torch.tensor(\n",
        "    nodes[\"label\"].values,\n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "sensitive = torch.tensor(\n",
        "    (nodes[\"region\"] == \"Bratislava\").astype(int).values,\n",
        "    dtype=torch.long\n",
        ")\n",
        "X.shape, y.shape, sensitive.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcbnUVGTSUvq",
        "outputId": "8536663a-f8d3-405c-93e1-4bfc774d26c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10262, 276]), torch.Size([10262]), torch.Size([10262]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsl9p_UpWf38"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = torch.tensor(\n",
        "    scaler.fit_transform(X),\n",
        "    dtype=torch.float\n",
        ")"
      ],
      "metadata": {
        "id": "0bNNGFoXSbIx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = pd.read_csv(\n",
        "    \"fairness-graph-gnn/datasets/region_job_relationship.txt\",\n",
        "    sep=\"\\t\",\n",
        "    names=[\"src\", \"dst\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "PaVwm9HnA8-d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GCNs require node indices from 0 … N-1. Pokec user IDs are arbitrary.\n",
        "\n",
        "id_map = {\n",
        "    uid: i for i, uid in enumerate(nodes[\"user_id\"].values)\n",
        "}\n",
        "\n",
        "src_list = []\n",
        "dst_list = []\n",
        "\n",
        "for src, dst in zip(edges[\"src\"], edges[\"dst\"]):\n",
        "    if src in id_map and dst in id_map:\n",
        "        src_list.append(id_map[src])\n",
        "        dst_list.append(id_map[dst])\n",
        "\n",
        "edge_index = torch.tensor(\n",
        "    [src_list, dst_list],\n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "# make undirected\n",
        "edge_index = torch.cat(\n",
        "    [edge_index, edge_index.flip(0)],\n",
        "    dim=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "qnyMFweoBEWC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index.min(), edge_index.max(), X.size(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjFbxyqTWnmS",
        "outputId": "c22e2121-6674-4a2d-f8e6-fadc82aa02fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), tensor(10260), 10262)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = nodes.shape[0]\n",
        "\n",
        "perm = torch.randperm(num_nodes)\n",
        "\n",
        "train_size = int(0.6 * num_nodes)\n",
        "val_size   = int(0.2 * num_nodes)\n",
        "\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "val_mask   = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[perm[:train_size]] = True\n",
        "val_mask[perm[train_size:train_size+val_size]] = True\n",
        "test_mask[perm[train_size+val_size:]] = True\n"
      ],
      "metadata": {
        "id": "s-NaRILxSqJn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "data = Data(\n",
        "    x=X,\n",
        "    edge_index=edge_index,\n",
        "    y=y\n",
        ")\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.val_mask = val_mask\n",
        "data.test_mask = test_mask\n",
        "data.sensitive = sensitive\n"
      ],
      "metadata": {
        "id": "yqWp1vUkSz5w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SupervisedGCN(torch.nn.Module):\n",
        "    def __init__(self, encoder, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.classifier = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        z = self.encoder(x, edge_index)\n",
        "        out = self.classifier(z)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "fYZmb5nvS9Gh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "encoder = GCNEncoder(\n",
        "    in_channels=data.num_features,\n",
        "    hidden_channels=64\n",
        ")\n",
        "\n",
        "model = SupervisedGCN(\n",
        "    encoder=encoder,\n",
        "    hidden_dim=64,\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "\n",
        "data = data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    weight_decay=5e-4\n",
        ")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "B9tT4vJJTEJv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct = (pred[mask] == data.y[mask]).sum()\n",
        "    acc = int(correct) / int(mask.sum())\n",
        "    return acc\n",
        "\n"
      ],
      "metadata": {
        "id": "992T0fyWTGSw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def fairness_metrics(y_true, y_pred, sensitive):\n",
        "    \"\"\"\n",
        "    y_true: (N,) ground truth labels {0,1}\n",
        "    y_pred: (N,) predicted labels {0,1}\n",
        "    sensitive: (N,) sensitive attribute {0,1}\n",
        "    \"\"\"\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    for s_val in [0, 1]:\n",
        "        mask_s = (sensitive == s_val)\n",
        "\n",
        "        # P(ŷ = 1 | s)\n",
        "        if mask_s.sum() > 0:\n",
        "            metrics[f\"P_yhat1_s{s_val}\"] = y_pred[mask_s].float().mean()\n",
        "        else:\n",
        "            metrics[f\"P_yhat1_s{s_val}\"] = torch.tensor(0.0)\n",
        "\n",
        "        # P(ŷ = 1 | y = 1, s)\n",
        "        mask_y1_s = mask_s & (y_true == 1)\n",
        "        if mask_y1_s.sum() > 0:\n",
        "            metrics[f\"TPR_s{s_val}\"] = y_pred[mask_y1_s].float().mean()\n",
        "        else:\n",
        "            metrics[f\"TPR_s{s_val}\"] = torch.tensor(0.0)\n",
        "\n",
        "    # Fairness gaps\n",
        "    delta_sp = torch.abs(\n",
        "        metrics[\"P_yhat1_s0\"] - metrics[\"P_yhat1_s1\"]\n",
        "    )\n",
        "\n",
        "    delta_eo = torch.abs(\n",
        "        metrics[\"TPR_s0\"] - metrics[\"TPR_s1\"]\n",
        "    )\n",
        "\n",
        "    return delta_sp.item(), delta_eo.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    acc = (pred[mask] == data.y[mask]).float().mean().item()\n",
        "\n",
        "    delta_sp, delta_eo = fairness_metrics(\n",
        "        y_true=data.y[mask],\n",
        "        y_pred=pred[mask],\n",
        "        sensitive=data.sensitive[mask]\n",
        "    )\n",
        "\n",
        "    return acc, delta_sp, delta_eo\n"
      ],
      "metadata": {
        "id": "ux_Xq65VYICH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "data = data.to(device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "mfDbFNSaTXy5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        train_acc, _, _ = evaluate(data.train_mask)\n",
        "        val_acc, val_sp, val_eo = evaluate(data.val_mask)\n",
        "        test_acc, test_sp, test_eo = evaluate(data.test_mask)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | \"\n",
        "            f\"Loss {loss:.4f} | \"\n",
        "            f\"Train {train_acc:.3f} | \"\n",
        "            f\"Val {val_acc:.3f} | \"\n",
        "            f\"Test {test_acc:.3f} | \"\n",
        "            f\"ΔSP {test_sp:.3f} | \"\n",
        "            f\"ΔEO {test_eo:.3f}\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00yBxiiDTHI4",
        "outputId": "5ca81a52-b80d-41c1-9cb5-0669b193a919"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 020 | Loss 0.4891 | Train 0.756 | Val 0.687 | Test 0.693 | ΔSP 0.462 | ΔEO 0.642\n",
            "Epoch 040 | Loss 0.3506 | Train 0.839 | Val 0.672 | Test 0.691 | ΔSP 0.526 | ΔEO 0.698\n",
            "Epoch 060 | Loss 0.2260 | Train 0.896 | Val 0.656 | Test 0.683 | ΔSP 0.599 | ΔEO 0.758\n",
            "Epoch 080 | Loss 0.1439 | Train 0.944 | Val 0.659 | Test 0.675 | ΔSP 0.504 | ΔEO 0.663\n",
            "Epoch 100 | Loss 0.1961 | Train 0.905 | Val 0.674 | Test 0.687 | ΔSP 0.495 | ΔEO 0.667\n",
            "Epoch 120 | Loss 0.1545 | Train 0.947 | Val 0.665 | Test 0.686 | ΔSP 0.544 | ΔEO 0.710\n",
            "Epoch 140 | Loss 0.0962 | Train 0.973 | Val 0.657 | Test 0.676 | ΔSP 0.534 | ΔEO 0.693\n",
            "Epoch 160 | Loss 0.0607 | Train 0.989 | Val 0.651 | Test 0.670 | ΔSP 0.535 | ΔEO 0.688\n",
            "Epoch 180 | Loss 0.0389 | Train 0.997 | Val 0.652 | Test 0.667 | ΔSP 0.537 | ΔEO 0.686\n",
            "Epoch 200 | Loss 0.1076 | Train 0.902 | Val 0.628 | Test 0.634 | ΔSP 0.633 | ΔEO 0.744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gvru0y67WFC1"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}