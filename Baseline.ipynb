{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_8srpJnAyeS",
        "outputId": "59243537-1c8c-4f76-b124-1e82602841d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.0+cu121 (from versions: 2.2.0+cu121, 2.2.1+cu121, 2.2.2+cu121, 2.3.0+cu121, 2.3.1+cu121, 2.4.0+cu121, 2.4.1+cu121, 2.5.0+cu121, 2.5.1+cu121)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.0+cu121\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ===== PyTorch (CUDA 12.1) =====\n",
        "!pip install -q torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# ===== PyTorch Geometric (prebuilt wheels, no compilation) =====\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "# ===== Fairness + utilities =====\n",
        "!pip install -q fairlearn scikit-learn pandas numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Uje4FuYuA4RY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ananyabatra04/fairness-graph-gnn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hObEnkCJLXhb",
        "outputId": "9ad4177c-2ec7-421c-e46d-594d797c330f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairness-graph-gnn'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 0 (delta 0), pack-reused 22 (from 1)\u001b[K\n",
            "Receiving objects: 100% (22/22), 52.28 MiB | 10.71 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Updating files: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = pd.read_csv(\"fairness-graph-gnn/datasets/region_job.csv\")\n",
        "feature_cols = [\n",
        "    c for c in nodes.columns\n",
        "    if c not in [\"user_id\", \"region\", \"I_am_working_in_field\"]\n",
        "]\n",
        "nodes[\"I_am_working_in_field\"].value_counts().sort_index()\n",
        "\n",
        "# Drop unknown labels\n",
        "nodes = nodes[nodes[\"I_am_working_in_field\"] != -1]\n",
        "\n",
        "# Binarize: 0 -> 0, 1–4 -> 1\n",
        "nodes[\"label\"] = (nodes[\"I_am_working_in_field\"] > 0).astype(int)\n",
        "\n",
        "nodes[\"label\"].value_counts()\n",
        "nodes[\"label\"].unique()\n"
      ],
      "metadata": {
        "id": "TXZNMIv9A5cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3c259a-25c0-4475-a66b-5b64559a1cb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor(\n",
        "    nodes[feature_cols].values,\n",
        "    dtype=torch.float\n",
        ")\n",
        "\n",
        "X = (X - X.mean(dim=0)) / (X.std(dim=0) + 1e-6) #normalization\n",
        "\n",
        "\n",
        "y = torch.tensor(\n",
        "    nodes[\"label\"].values,\n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "sensitive = torch.tensor(\n",
        "    (nodes[\"region\"] == \"Bratislava\").astype(int).values,\n",
        "    dtype=torch.long\n",
        ")\n",
        "X.shape, y.shape, sensitive.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcbnUVGTSUvq",
        "outputId": "a4c3b756-3208-43df-aa8a-2c0fa358651e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10262, 276]), torch.Size([10262]), torch.Size([10262]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsl9p_UpWf38"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = torch.tensor(\n",
        "    scaler.fit_transform(X),\n",
        "    dtype=torch.float\n",
        ")"
      ],
      "metadata": {
        "id": "0bNNGFoXSbIx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = pd.read_csv(\n",
        "    \"fairness-graph-gnn/datasets/region_job_relationship.txt\",\n",
        "    sep=\"\\t\",\n",
        "    names=[\"src\", \"dst\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "PaVwm9HnA8-d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GCNs require node indices from 0 … N-1. Pokec user IDs are arbitrary.\n",
        "\n",
        "id_map = {\n",
        "    uid: i for i, uid in enumerate(nodes[\"user_id\"].values)\n",
        "}\n",
        "\n",
        "src_list = []\n",
        "dst_list = []\n",
        "\n",
        "for src, dst in zip(edges[\"src\"], edges[\"dst\"]):\n",
        "    if src in id_map and dst in id_map:\n",
        "        src_list.append(id_map[src])\n",
        "        dst_list.append(id_map[dst])\n",
        "\n",
        "edge_index = torch.tensor(\n",
        "    [src_list, dst_list],\n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "# make undirected\n",
        "edge_index = torch.cat(\n",
        "    [edge_index, edge_index.flip(0)],\n",
        "    dim=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "qnyMFweoBEWC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index.min(), edge_index.max(), X.size(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjFbxyqTWnmS",
        "outputId": "48e762d2-95f1-455e-9e7f-0492d21396c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), tensor(10260), 10262)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = nodes.shape[0]\n",
        "\n",
        "perm = torch.randperm(num_nodes)\n",
        "\n",
        "train_size = int(0.6 * num_nodes)\n",
        "val_size   = int(0.2 * num_nodes)\n",
        "\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "val_mask   = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[perm[:train_size]] = True\n",
        "val_mask[perm[train_size:train_size+val_size]] = True\n",
        "test_mask[perm[train_size+val_size:]] = True\n"
      ],
      "metadata": {
        "id": "s-NaRILxSqJn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "data = Data(\n",
        "    x=X,\n",
        "    edge_index=edge_index,\n",
        "    y=y\n",
        ")\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.val_mask = val_mask\n",
        "data.test_mask = test_mask\n",
        "data.sensitive = sensitive\n"
      ],
      "metadata": {
        "id": "yqWp1vUkSz5w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fYZmb5nvS9Gh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = GCN(\n",
        "    in_channels=data.num_features,\n",
        "    hidden_channels=64,\n",
        "    out_channels=2\n",
        ").to(device)\n",
        "\n",
        "data = data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    weight_decay=5e-4\n",
        ")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "B9tT4vJJTEJv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct = (pred[mask] == data.y[mask]).sum()\n",
        "    acc = int(correct) / int(mask.sum())\n",
        "    return acc\n",
        "\n"
      ],
      "metadata": {
        "id": "992T0fyWTGSw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def fairness_metrics(y_true, y_pred, sensitive):\n",
        "    \"\"\"\n",
        "    y_true: (N,) ground truth labels {0,1}\n",
        "    y_pred: (N,) predicted labels {0,1}\n",
        "    sensitive: (N,) sensitive attribute {0,1}\n",
        "    \"\"\"\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    for s_val in [0, 1]:\n",
        "        mask_s = (sensitive == s_val)\n",
        "\n",
        "        # P(ŷ = 1 | s)\n",
        "        if mask_s.sum() > 0:\n",
        "            metrics[f\"P_yhat1_s{s_val}\"] = y_pred[mask_s].float().mean()\n",
        "        else:\n",
        "            metrics[f\"P_yhat1_s{s_val}\"] = torch.tensor(0.0)\n",
        "\n",
        "        # P(ŷ = 1 | y = 1, s)\n",
        "        mask_y1_s = mask_s & (y_true == 1)\n",
        "        if mask_y1_s.sum() > 0:\n",
        "            metrics[f\"TPR_s{s_val}\"] = y_pred[mask_y1_s].float().mean()\n",
        "        else:\n",
        "            metrics[f\"TPR_s{s_val}\"] = torch.tensor(0.0)\n",
        "\n",
        "    # Fairness gaps\n",
        "    delta_sp = torch.abs(\n",
        "        metrics[\"P_yhat1_s0\"] - metrics[\"P_yhat1_s1\"]\n",
        "    )\n",
        "\n",
        "    delta_eo = torch.abs(\n",
        "        metrics[\"TPR_s0\"] - metrics[\"TPR_s1\"]\n",
        "    )\n",
        "\n",
        "    return delta_sp.item(), delta_eo.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    acc = (pred[mask] == data.y[mask]).float().mean().item()\n",
        "\n",
        "    delta_sp, delta_eo = fairness_metrics(\n",
        "        y_true=data.y[mask],\n",
        "        y_pred=pred[mask],\n",
        "        sensitive=data.sensitive[mask]\n",
        "    )\n",
        "\n",
        "    return acc, delta_sp, delta_eo\n"
      ],
      "metadata": {
        "id": "ux_Xq65VYICH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "data = data.to(device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "mfDbFNSaTXy5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        train_acc, _, _ = evaluate(data.train_mask)\n",
        "        val_acc, val_sp, val_eo = evaluate(data.val_mask)\n",
        "        test_acc, test_sp, test_eo = evaluate(data.test_mask)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | \"\n",
        "            f\"Loss {loss:.4f} | \"\n",
        "            f\"Train {train_acc:.3f} | \"\n",
        "            f\"Val {val_acc:.3f} | \"\n",
        "            f\"Test {test_acc:.3f} | \"\n",
        "            f\"ΔSP {test_sp:.3f} | \"\n",
        "            f\"ΔEO {test_eo:.3f}\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00yBxiiDTHI4",
        "outputId": "9ad4d2ee-ef4d-4193-bbca-40aa7ebe59be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 020 | Loss 0.2804 | Train 0.914 | Val 0.684 | Test 0.691 | ΔSP 0.524 | ΔEO 0.695\n",
            "Epoch 040 | Loss 0.2741 | Train 0.923 | Val 0.679 | Test 0.692 | ΔSP 0.505 | ΔEO 0.678\n",
            "Epoch 060 | Loss 0.2677 | Train 0.923 | Val 0.672 | Test 0.681 | ΔSP 0.513 | ΔEO 0.676\n",
            "Epoch 080 | Loss 0.2656 | Train 0.921 | Val 0.674 | Test 0.688 | ΔSP 0.495 | ΔEO 0.666\n",
            "Epoch 100 | Loss 0.2621 | Train 0.916 | Val 0.676 | Test 0.686 | ΔSP 0.495 | ΔEO 0.665\n",
            "Epoch 120 | Loss 0.2620 | Train 0.926 | Val 0.673 | Test 0.686 | ΔSP 0.519 | ΔEO 0.686\n",
            "Epoch 140 | Loss 0.2586 | Train 0.931 | Val 0.677 | Test 0.684 | ΔSP 0.513 | ΔEO 0.679\n",
            "Epoch 160 | Loss 0.2577 | Train 0.925 | Val 0.683 | Test 0.687 | ΔSP 0.517 | ΔEO 0.685\n",
            "Epoch 180 | Loss 0.2551 | Train 0.934 | Val 0.667 | Test 0.688 | ΔSP 0.513 | ΔEO 0.683\n",
            "Epoch 200 | Loss 0.2476 | Train 0.937 | Val 0.670 | Test 0.679 | ΔSP 0.517 | ΔEO 0.677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gvru0y67WFC1"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}